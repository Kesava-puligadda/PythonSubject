{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP7_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZzV807C2Ecy"
      },
      "source": [
        "####### Here initially we will import the required libraries #######\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import nltk\n",
        "\n",
        "####### here we search the files with given url & and save them into text file  #######\n",
        "\n",
        "def search_spider():\n",
        "\n",
        "    url = \"https://en.wikipedia.org/wiki/Google\"\n",
        "    source_code = urllib.request.urlopen(url)\n",
        "    soup = BeautifulSoup(source_code, \"html.parser\")\n",
        "    body = soup.find('div', {'class': 'mw-parser-output'})\n",
        "\n",
        "    file = open('input.txt', 'a+', encoding='utf-8')\n",
        "    file.write(str(body.text))\n",
        "search_spider()\n",
        "\n",
        "matter = open('input.txt', encoding=\"utf8\").read()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4InkEAt8YYf",
        "outputId": "837a5a91-0cf2-4e22-acbf-a60830fc61e7"
      },
      "source": [
        "#Tokenization\n",
        "import nltk\n",
        "\n",
        "stokens = nltk.sent_tokenize(matter)\n",
        "wtokens = nltk.word_tokenize(matter)\n",
        "\n",
        "print(wtokens[:32])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['American', 'technology', 'company', 'This', 'article', 'is', 'about', 'the', 'company', '.', 'For', 'the', 'search', 'engine', ',', 'see', 'Google', 'Search', '.', 'For', 'other', 'uses', ',', 'see', 'Google', '(', 'disambiguation', ')', '.', 'Not', 'to', 'be']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5emiYGy0_FB1",
        "outputId": "a37b30dd-ef68-4fc0-a084-cbd2e7c388f9"
      },
      "source": [
        "print(stokens[:13])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['American technology company\\nThis article is about the company.', 'For the search engine, see Google Search.', 'For other uses, see Google (disambiguation).', 'Not to be confused with Googol or Goggles.', 'It has been suggested that .google be merged into this article.', '(Discuss) Proposed since April 2021.', \"Google LLCLogo since 2015[update]Google's headquarters, the GoogleplexFormerlyGoogle Inc. (1998â€“2017)TypeSubsidiary (LLC)IndustryInternetCloud computingComputer softwareComputer hardwareArtificial intelligenceAdvertisingFoundedSeptember\\xa04, 1998; 22 years ago\\xa0(1998-09-04)[a] in Menlo Park, California, United StatesFoundersLarry PageSergey BrinHeadquarters1600 Amphitheatre Parkway, Mountain View, California, United StatesQueenstown, Singapore (Asia-Pacific)[5]Area servedWorldwideKey peopleSundar Pichai (CEO)Ruth Porat (CFO)ProductsList of productsRevenue182,527,000,000 United States dollar (2020)\\xa0Operating income41,224,000,000 United States dollar (2020)\\xa0Net income40,269,000,000 United States dollar (2020)\\xa0Total assets319,616,000,000 United States dollar (2020)\\xa0Number of employees135,301 (2020)\\xa0ParentAlphabet Inc.Websitegoogle.comFootnotes\\xa0/ references[6][7][8][9]\\nGoogle LLC is an American multinational technology company that specializes in Internet-related services and products, which include online advertising technologies, a search engine, cloud computing, software, and hardware.\", 'It is considered one of the Big Five technology companies in the U.S. information technology industry, alongside Amazon, Facebook, Apple, and Microsoft.', '[10][11][12]\\nGoogle was founded in September 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California.', 'Together they own about 14 percent of its shares and control 56 percent of the stockholder voting power through supervoting stock.', 'They incorporated Google as a California privately held company on September 4, 1998.', 'Google was then reincorporated in Delaware on October 22, 2002.', '[13] An initial public offering (IPO) took place on August 19, 2004, and Google moved to its headquarters in Mountain View, California, nicknamed the  Googleplex.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frE7Y-1X_N9l",
        "outputId": "3e584689-6241-4e1c-9d2b-09e38da755ad"
      },
      "source": [
        "#Part of Speech (POS)\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "n1 = 0\n",
        "for t in wtokens:\n",
        "    n1 = n1 + 1\n",
        "    if n1 < 6:\n",
        "        print('Sentence    : ', t)\n",
        "        print(nltk.pos_tag(t))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "Sentence    :  American\n",
            "[('A', 'DT'), ('m', 'NN'), ('e', 'NN'), ('r', 'NN'), ('i', 'NN'), ('c', 'VBP'), ('a', 'DT'), ('n', 'NN')]\n",
            "Sentence    :  technology\n",
            "[('t', 'NN'), ('e', 'NN'), ('c', 'NN'), ('h', 'NN'), ('n', 'JJ'), ('o', 'NN'), ('l', 'NN'), ('o', 'NN'), ('g', 'NN'), ('y', 'NN')]\n",
            "Sentence    :  company\n",
            "[('c', 'NNS'), ('o', 'VBP'), ('m', 'JJ'), ('p', 'NN'), ('a', 'DT'), ('n', 'JJ'), ('y', 'NN')]\n",
            "Sentence    :  This\n",
            "[('T', 'NNP'), ('h', 'NN'), ('i', 'NN'), ('s', 'VBP')]\n",
            "Sentence    :  article\n",
            "[('a', 'DT'), ('r', 'NN'), ('t', 'NN'), ('i', 'NN'), ('c', 'VBP'), ('l', 'NN'), ('e', 'NN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YSnqcDdEQFW",
        "outputId": "01fde0d6-2d9f-4054-ea6f-11b57becd903"
      },
      "source": [
        "#Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "pStemmer = PorterStemmer()\n",
        "lStemmer = LancasterStemmer()\n",
        "sStemmer = SnowballStemmer('english')\n",
        "\n",
        "n1 = 0\n",
        "for t in wtokens:\n",
        "    n1 = n1 + 1\n",
        "    if n1 < 6:\n",
        "        print('pStemmer : ' ,pStemmer.stem(t))\n",
        "        print('lStemmer : ' ,lStemmer.stem(t))\n",
        "        print('sStemmer : ' ,sStemmer.stem(t))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pStemmer :  american\n",
            "lStemmer :  am\n",
            "sStemmer :  american\n",
            "pStemmer :  technolog\n",
            "lStemmer :  technolog\n",
            "sStemmer :  technolog\n",
            "pStemmer :  compani\n",
            "lStemmer :  company\n",
            "sStemmer :  compani\n",
            "pStemmer :  thi\n",
            "lStemmer :  thi\n",
            "sStemmer :  this\n",
            "pStemmer :  articl\n",
            "lStemmer :  artic\n",
            "sStemmer :  articl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I0QS56zExpy",
        "outputId": "a377f3ce-e575-45e4-efc5-ebbaabcfc2b2"
      },
      "source": [
        "#lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "n1 = 0\n",
        "for w in wtokens:\n",
        "    n1 = n1 + 1\n",
        "    if n1 < 6:\n",
        "        print('Lemmatizer:', lemmatizer.lemmatize(w))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemmatizer: American\n",
            "Lemmatizer: technology\n",
            "Lemmatizer: company\n",
            "Lemmatizer: This\n",
            "Lemmatizer: article\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PejkSLm1FM4j",
        "outputId": "2180ecbf-3c9e-4fe7-fee1-6a47487fa4a2"
      },
      "source": [
        "#trigram\n",
        "from nltk.util import ngrams\n",
        "token = nltk.word_tokenize(matter)\n",
        "\n",
        "n = 0\n",
        "for s in stokens:\n",
        "    n = n + 1\n",
        "    if n < 2:\n",
        "        print('Sentence    : ', s)\n",
        "        token = nltk.word_tokenize(s)\n",
        "        print('wordtoken : ', token)\n",
        "        bigrams = list(ngrams(token, 2))\n",
        "        print('bigram     : ', bigrams)\n",
        "        trigrams = list(ngrams(token, 3))\n",
        "        print('trigram   : ', trigrams)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence    :  American technology company\n",
            "This article is about the company.\n",
            "wordtoken :  ['American', 'technology', 'company', 'This', 'article', 'is', 'about', 'the', 'company', '.']\n",
            "bigram     :  [('American', 'technology'), ('technology', 'company'), ('company', 'This'), ('This', 'article'), ('article', 'is'), ('is', 'about'), ('about', 'the'), ('the', 'company'), ('company', '.')]\n",
            "trigram   :  [('American', 'technology', 'company'), ('technology', 'company', 'This'), ('company', 'This', 'article'), ('This', 'article', 'is'), ('article', 'is', 'about'), ('is', 'about', 'the'), ('about', 'the', 'company'), ('the', 'company', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaAwOWDzFxjN",
        "outputId": "7c29a96e-e419-454d-fa93-ca4354a1f86a"
      },
      "source": [
        "#Named Entity Recognition (NOS)\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "nltk.download('words')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "n = 0\n",
        "for s in stokens:\n",
        "    n = n + 1\n",
        "    if n < 2:\n",
        "        print(s)\n",
        "        print(ne_chunk(pos_tag(word_tokenize(s))))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "American technology company\n",
            "This article is about the company.\n",
            "(S\n",
            "  (GPE American/NNP)\n",
            "  technology/NN\n",
            "  company/NN\n",
            "  This/DT\n",
            "  article/NN\n",
            "  is/VBZ\n",
            "  about/IN\n",
            "  the/DT\n",
            "  company/NN\n",
            "  ./.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCdTff5X-pg6"
      },
      "source": [
        ""
      ],
      "execution_count": 74,
      "outputs": []
    }
  ]
}